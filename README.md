# Regulatory-Misalignment-Anthropic-Case-Study
This repository extends Anthropic's constitutional AI alignment framework to the organizational layer, providing interpretability tools for recursive governance auditing. We apply the same principles of transparency, verifiability, and alignment that Anthropic champions for AI systems to the organizational structures that create them
